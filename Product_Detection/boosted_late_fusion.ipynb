{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "import os, time, datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, f1_score, roc_curve, auc\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
    "\n",
    "class SigirPreprocess():\n",
    "    \n",
    "    def __init__(self, text_data_path):\n",
    "        self.text_data_path = text_data_path\n",
    "        self.train = None\n",
    "        self.dict_code_to_id = {}\n",
    "        self.dict_id_to_code = {}\n",
    "        self.list_tags = {}\n",
    "        self.sentences = []\n",
    "        self.labels = []\n",
    "        self.text_col = None\n",
    "        self.X_test = None\n",
    "        \n",
    "    def prepare_data(self ):\n",
    "        catalog_eng= pd.read_csv(self.text_data_path+\"data/catalog_english_taxonomy.tsv\",sep=\"\\t\")\n",
    "        X_train= pd.read_csv(self.text_data_path+\"data/X_train.tsv\",sep=\"\\t\")\n",
    "        Y_train= pd.read_csv(self.text_data_path+\"data/Y_train.tsv\",sep=\"\\t\")\n",
    "        \n",
    "        self.list_tags = list(Y_train['Prdtypecode'].unique())\n",
    "        for i,tag in enumerate(self.list_tags):\n",
    "            self.dict_code_to_id[tag] = i \n",
    "            self.dict_id_to_code[i]=tag\n",
    "        print(self.dict_code_to_id)\n",
    "            \n",
    "        Y_train['labels']=Y_train['Prdtypecode'].map(self.dict_code_to_id)\n",
    "        train=pd.merge(left=X_train,right=Y_train,\n",
    "               how='left',left_on=['Integer_id','Image_id','Product_id'],\n",
    "               right_on=['Integer_id','Image_id','Product_id'])\n",
    "        prod_map=pd.Series(catalog_eng['Top level category'].values,\n",
    "                           index=catalog_eng['Prdtypecode']).to_dict()\n",
    "\n",
    "        train['product'] = train['Prdtypecode'].map(prod_map)\n",
    "        train['title_len']=train['Title'].progress_apply(lambda x : len(x.split()) if pd.notna(x) else 0)\n",
    "        train['desc_len']=train['Description'].progress_apply(lambda x : len(x.split()) if pd.notna(x) else 0)\n",
    "        train['title_desc_len']=train['title_len'] + train['desc_len']\n",
    "        train.loc[train['Description'].isnull(), 'Description'] = \" \"\n",
    "        train['title_desc'] = train['Title'] + \" \" + train['Description']\n",
    "        \n",
    "        self.train = train\n",
    "        \n",
    "    def get_sentences(self, text_col, remove_null_rows=False):\n",
    "        self.text_col = text_col\n",
    "        if remove_null_rows==True:\n",
    "            new_train = self.train[self.train[text_col].notnull()]\n",
    "\n",
    "        else:\n",
    "            new_train = self.train.copy()\n",
    "            \n",
    "        self.sentences = new_train[text_col].values\n",
    "        self.labels = new_train['labels'].values\n",
    "    \n",
    "    def prepare_test(self, text_col, test_data_path, phase=1):\n",
    "        X_test=pd.read_csv(test_data_path+f\"data/x_test_task1_phase{phase}.tsv\",sep=\"\\t\")\n",
    "        X_test.loc[X_test['Description'].isnull(), 'Description'] = \" \"\n",
    "        X_test['title_desc'] = X_test['Title'] + \" \" + X_test['Description']\n",
    "        self.X_test = X_test\n",
    "        self.test_sentences = X_test[text_col].values\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_col = 'title_desc'\n",
    "val_size = 0.1\n",
    "random_state=2020\n",
    "num_class = 27\n",
    "do_gridsearch = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {'add_logits':['cam', 'fla']}\n",
    "\n",
    "\n",
    "cam_path = '/../input/camembert-vec-256m768-10ep/'\n",
    "flau_path = '/../input/flaubertlogits2107/' \n",
    "res_path = '/../input/resnextfinal/'\n",
    "cms_path = '/../input/crossmodal-v0/'\n",
    "vca_path = '/../input/vec-concat-9093/'\n",
    "vca_path_phase2 = '/../input/predictions-test-phase2-vec-fusion/'\n",
    "aem_path = '/../input/addition-ensemble-latest/'\n",
    "\n",
    "\n",
    "val_logits_path = {'cam':cam_path + 'validation_set_softmax_logits.npy',\n",
    "              'fla':flau_path + 'validation_set_softmax_logits.npy',\n",
    "              'res':res_path + 'Valid_resnext50_32x4d_phase1_softmax_logits.npy',\n",
    "                'vca':vca_path + 'softmax_logits_val_9093.npy',\n",
    "                  'aem':aem_path + 'softmax_logits_val_add.npy'}\n",
    "\n",
    "test_logits_path_phase1 = {'cam':cam_path+f'X_test_phase1_softmax_logits.npy',\n",
    "              'fla':flau_path + f'X_test_phase1_softmax_logits.npy', \n",
    "              'res':res_path + f'Test_resnext50_32x4d_phase1_softmax_logits.npy',\n",
    "                'vca':vca_path + f'softmax_logits_test_9093.npy'}\n",
    "\n",
    "test_logits_path_phase2 = {'cam':cam_path+f'X_test_phase2_softmax_logits.npy',\n",
    "                  'fla':flau_path + f'X_test_phase2_softmax_logits.npy', \n",
    "                  'res':res_path + f'Test_resnext50_32x4d_phase2_softmax_logits.npy',\n",
    "                    'vca':vca_path_phase2 + f'softmax_logits_test_phase2_9093.npy'}\n",
    "                           \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get valdation dataset from original train dataset\n",
    "Preprocess = SigirPreprocess(\"/../input/textphase1/\")\n",
    "Preprocess.prepare_data()\n",
    "Preprocess.get_sentences(text_col, True)\n",
    "\n",
    "full_data = Preprocess.train\n",
    "labels = Preprocess.labels\n",
    "index = full_data.Integer_id\n",
    "\n",
    "\n",
    "tr_index, val_index, tr_labels, val_labels = train_test_split(index, labels,\n",
    "                                                    stratify=labels,\n",
    "                                                    random_state=random_state, \n",
    "                                                    test_size=val_size)\n",
    "\n",
    "train_data = full_data.loc[tr_index, :]\n",
    "train_data.reset_index(inplace=True, drop=True)\n",
    "val_data = full_data.loc[val_index, :]\n",
    "val_data.reset_index(inplace=True, drop=True)\n",
    "\n",
    "full_data.loc[val_index, 'sample'] = 'val'\n",
    "full_data['sample'].fillna('train', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preparelogits_df(logit_paths, df=None, val_labels=None, **kwargs):\n",
    "    ### Prepare and combine Logits data with original validation dataset\n",
    "    logits_dict = {}\n",
    "    dfs_dict = {}\n",
    "    for key, logit_path in logit_paths.items():\n",
    "        logits_dict[key] = np.load(logit_path)\n",
    "        \n",
    "        dfs_dict[key] = pd.DataFrame(logits_dict[key], \n",
    "                                     columns=[key + \"_\" + str(i) for i in range(1,28)])\n",
    "        print(\"Shape of logit arrays: {}\", logits_dict[key].shape)\n",
    "        \n",
    "    if kwargs['add_logits']:\n",
    "        if len(kwargs['add_logits'])>0:\n",
    "            add_str = '_'.join(kwargs['add_logits'])\n",
    "            logits_dict[add_str] = logits_dict[kwargs['add_logits'][0]]\n",
    "            for k in kwargs['add_logits'][1:]:\n",
    "                logits_dict[add_str] += logits_dict[k]\n",
    "            logits_dict[add_str] = logits_dict[add_str]/len(kwargs['add_logits'])\n",
    "            dfs_dict[add_str] = pd.DataFrame(logits_dict[add_str], \n",
    "                                     columns=[add_str + \"_\" + str(i) for i in range(1,28)])\n",
    "            print(\"Shape of logit arrays: {}\", logits_dict[add_str].shape)\n",
    "\n",
    "\n",
    "    \n",
    "    if type(val_labels) == np.ndarray:\n",
    "        for key,logits in logits_dict.items():\n",
    "            print(\"\"\"Validation F1 scores for {} logits: {} \"\"\".format(key, \n",
    "                f1_score(val_labels, np.argmax(logits, axis=1), average='macro')))\n",
    "            \n",
    "    \n",
    "\n",
    "    df = pd.concat([df] + list(dfs_dict.values()), axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = preparelogits_df(val_logits_path, df=val_data, \n",
    "                            val_labels=val_labels, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_log = val_data.copy()\n",
    "\n",
    "probas_cols = [\"fla_\" + str(i) for i in range(1,28)] + [\"cam_\" + str(i) for i in range(1,28)] +\\\n",
    "[\"res_\" + str(i) for i in range(1,28)] \\\n",
    "+ [\"vca_\" + str(i) for i in range(1,28)] \\\n",
    "\n",
    "X = df_log[probas_cols]\n",
    "y = df_log['labels'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=random_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import randint as sp_randint\n",
    "from scipy.stats import uniform as sp_uniform\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "n_HP_points_to_test = 100\n",
    "\n",
    "\n",
    "param_test ={'num_leaves': sp_randint(6, 50), \n",
    "             'min_child_samples': sp_randint(100, 500), \n",
    "             'min_child_weight': [1e-5, 1e-3, 1e-2, 1e-1, 1, 1e1, 1e2, 1e3, 1e4],\n",
    "             'subsample': sp_uniform(loc=0.2, scale=0.8), \n",
    "             'colsample_bytree': sp_uniform(loc=0.4, scale=0.6),\n",
    "             'reg_alpha': [0, 1e-1, 1, 2, 5, 7, 10, 50, 100],\n",
    "             'reg_lambda': [0, 1e-1, 1, 5, 10, 20, 50, 100],\n",
    "#              \"bagging_fraction\" : [0.5, 0.6, 0.7, 0.8, 0.9],\n",
    "#              \"feature_fraction\":[0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "            }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fit_params={\n",
    "            \"early_stopping_rounds\":100, \n",
    "            \"eval_metric\" : 'multi_logloss', \n",
    "            \"eval_set\" : [(X_test,y_test)],\n",
    "            'eval_names': ['valid'],\n",
    "            #'callbacks': [lgb.reset_parameter(learning_rate=learning_rate_010_decay_power_099)],\n",
    "            'verbose': 100,\n",
    "            'categorical_feature': 'auto'}\n",
    "\n",
    "\n",
    "clf = lgb.LGBMClassifier(num_iteration=1000, max_depth=-1, random_state=314, silent=True,\n",
    "                         metric='multi_logloss', n_jobs=4, early_stopping_rounds=100,\n",
    "                         num_class=num_class, objective= \"multiclass\")\n",
    "gs = RandomizedSearchCV(\n",
    "    estimator=clf, param_distributions=param_test, \n",
    "    n_iter=n_HP_points_to_test,\n",
    "    cv=3,\n",
    "    refit=True,\n",
    "    random_state=314,\n",
    "    verbose=True)\n",
    "\n",
    "if do_gridsearch==True:\n",
    "    gs.fit(X_train, y_train, **fit_params)\n",
    "    print('Best score reached: {} with params: {} '.format(gs.best_score_, gs.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opt_parameters = gs.best_params_\n",
    "opt_parameters = {'colsample_bytree': 0.5284213741879101, 'min_child_samples': 125, \n",
    "         'min_child_weight': 10.0, 'num_leaves': 22, \n",
    "         'reg_alpha': 0.1, 'reg_lambda': 20, 'subsample': 0.3080033455431848} \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run lightgbm to get weights for different class logits\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "model_met = 'fit' #'xgb'#'train' #fit\n",
    "\n",
    "params = {\n",
    "          \"objective\" : \"multiclass\",\n",
    "          \"num_class\" : num_class,\n",
    "          \"num_leaves\" : 60,\n",
    "          \"max_depth\": -1,\n",
    "          \"learning_rate\" : 0.01,\n",
    "          \"bagging_fraction\" : 0.9,  # subsample\n",
    "          \"feature_fraction\" : 0.9,  # colsample_bytree\n",
    "          \"bagging_freq\" : 5,        # subsample_freq\n",
    "          \"bagging_seed\" : 2018,\n",
    "          \"verbosity\" : -1 }\n",
    "\n",
    "lgtrain, lgval = lgb.Dataset(X_train, y_train), lgb.Dataset(X_test, y_test)\n",
    "\n",
    "if model_met == 'train':\n",
    "    params.update(opt_parameters)\n",
    "    params.update(fit_params)\n",
    "    \n",
    "    lgbmodel = lgb.train(params, lgtrain, valid_sets=[lgtrain, lgval], \n",
    "                         num_iterations = 1000, metric= 'multi_logloss')\n",
    "    train_logits = lgbmodel.predict(X_train) \n",
    "    test_logits = lgbmodel.predict(X_test)\n",
    "\n",
    "    train_pred = np.argmax(train_logits, axis=1) \n",
    "    test_pred = np.argmax(test_logits, axis=1) \n",
    "elif model_met == 'xgb':\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "    dtrain.save_binary('xgb_train.buffer')\n",
    "    dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "    \n",
    "    num_round = 200\n",
    "    xgb_param = {'max_depth': 5, 'eta': 0.1, 'seed':2020, 'verbosity':1,\n",
    "                 'objective': 'multi:softmax', 'num_class':num_class}\n",
    "    xgb_param['nthread'] = 4\n",
    "    xgb_param['eval_metric'] = 'mlogloss'\n",
    "    evallist = [(dtest, 'eval'), (dtrain, 'train')]\n",
    "    bst = xgb.train(xgb_param, dtrain, num_round, evallist\n",
    "                    , early_stopping_rounds=10\n",
    "                   )\n",
    "    \n",
    "    train_logits = bst.predict(xgb.DMatrix(X_train), ntree_limit=bst.best_ntree_limit) \n",
    "    test_logits = bst.predict(xgb.DMatrix(X_test), ntree_limit=bst.best_ntree_limit)\n",
    "\n",
    "    train_pred = train_logits \n",
    "    test_pred = test_logits \n",
    "    \n",
    "else:\n",
    "\n",
    "    lgbmodel = lgb.LGBMClassifier(**clf.get_params())\n",
    "    #set optimal parameters\n",
    "    lgbmodel.set_params(**opt_parameters)\n",
    "    lgbmodel.fit(X_train, y_train, **fit_params)\n",
    "    \n",
    "    train_logits = lgbmodel.predict(X_train) \n",
    "    test_logits = lgbmodel.predict(X_test)\n",
    "\n",
    "    train_pred = train_logits \n",
    "    test_pred = test_logits \n",
    "    \n",
    "print(\"Validation F1: {} and Training F1: {} \".format(\n",
    "    f1_score(y_test, test_pred, average='macro'), \n",
    "    f1_score(y_train, train_pred, average='macro')))\n",
    "\n",
    "if model_met == 'train':\n",
    "    feat_imp = pd.DataFrame({'feature':probas_cols, \n",
    "                             'logit_kind': [i.split('_')[0] for i in probas_cols],\n",
    "                             'imp':lgbmodel.feature_importance()/sum(lgbmodel.feature_importance())})\n",
    "\n",
    "\n",
    "    lgbmodel.save_model('lgb_classifier_81feats.txt', num_iteration=lgbmodel.best_iteration) \n",
    "    print(\"\"\"Feature Importances by logits group: \n",
    "          \"\"\", feat_imp.groupby(['logit_kind'])['imp'].sum())\n",
    "else:\n",
    "    feat_imp = pd.DataFrame({'feature':probas_cols, \n",
    "                             'logit_kind': [i.split('_')[0] for i in probas_cols],\n",
    "                             'imp':lgbmodel.feature_importances_/sum(lgbmodel.feature_importances_)})\n",
    "\n",
    "    print(\"\"\"Feature Importances by logits group: \n",
    "          \"\"\", feat_imp.groupby(['logit_kind'])['imp'].sum())\n",
    "    \n",
    "import shap\n",
    "explainer = shap.TreeExplainer(lgbmodel)\n",
    "shap_values = explainer.shap_values(X)\n",
    "print(\"Time Elapsed: {:}.\".format(format_time(time.time() - t0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n, path in enumerate(['/kaggle/input/textphase1/', \n",
    "                          '/kaggle/input/testphase2/']):\n",
    "    phase = n+1\n",
    "    if phase==1:\n",
    "        test_logits_path = test_logits_path_phase1\n",
    "    else:\n",
    "        test_logits_path = test_logits_path_phase2\n",
    "    Preprocess.prepare_test(text_col, path, phase)\n",
    "    X_test_phase1= Preprocess.X_test\n",
    "\n",
    "    test_phase1 = preparelogits_df(test_logits_path,\n",
    "                                df=X_test_phase1, val_labels=None, **kwargs)\n",
    "    \n",
    "    phase1_logits = lgbmodel.predict(test_phase1[probas_cols].values) \n",
    "    if model_met == 'train':\n",
    "        predictions = np.argmax(phase1_logits, axis=1) \n",
    "    elif model_met == 'xgb':\n",
    "        phase1_logits = bst.predict(xgb.DMatrix(test_phase1[probas_cols]), \n",
    "                                    ntree_limit=bst.best_ntree_limit) \n",
    "        predictions = phase1_logits\n",
    "    else:\n",
    "        predictions = phase1_logits\n",
    "    X_test_phase1['prediction_model']= predictions\n",
    "    X_test_phase1['Prdtypecode']=X_test_phase1['prediction_model'].map(Preprocess.dict_id_to_code)\n",
    "    print(X_test_phase1['Prdtypecode'].value_counts())\n",
    "    X_test_phase1=X_test_phase1.drop(['prediction_model','Title','Description'],axis=1)\n",
    "    X_test_phase1.to_csv(f'y_test_task1_phase{phase}_pred_.tsv',sep='\\t',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
